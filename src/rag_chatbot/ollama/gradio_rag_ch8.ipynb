{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import lancedb\n",
    "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, SimpleDirectoryReader\n",
    "import os\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "import pandas as pd\n",
    "from llama_index.core import ServiceContext\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "from graphrag.query.llm.oai.embedding import OpenAIEmbedding\n",
    "from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.question_gen.local_gen import LocalQuestionGen\n",
    "from graphrag.query.structured_search.local_search.mixed_context import (\n",
    "    LocalSearchMixedContext,\n",
    ")\n",
    "from graphrag.query.structured_search.local_search.search import LocalSearch\n",
    "from graphrag.vector_stores.lancedb import LanceDBVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settingsë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ë° LLM ì„¤ì •\n",
    "#Settings.embed_model = HuggingFaceEmbedding(model_name=\"bert-base-uncased\")  # 768 ì°¨ì›ì˜ ë²¡í„°ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸\n",
    "#Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "#all-mpnet-base-v2 (768ì°¨ì›, ì •í™•ë„ ë†’ìŒ, ì†ë„ ì¤‘ê°„)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "\n",
    "#Settings.embed_model = HuggingFaceEmbedding(model_name=\"gemma2\")\n",
    "\n",
    "# ğŸ“Œ Ollama ëª¨ë¸ ì„¤ì • (ë¡œì»¬ ëª¨ë¸ ì‚¬ìš©) \n",
    "#llm = OllamaLLM(model_name=\"gemma2\")  # Ollama ëª¨ë¸ ì„¤ì •\n",
    "#Settings.llm = llm\n",
    "\n",
    "\n",
    "llm = Ollama(model=\"gemma2\",base_url=\"http://localhost:11434/v1\")\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ GraphRAGì—ì„œ ìƒì„±í•œ LanceDB ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "#path = \"/Users/jun/GitStudy/Data_4/Data/project5/model/openaitest_0209/output/20250206-001434/artifacts\"\n",
    "path = \"/Users/jun/GitStudy/Data_4/Data/project5/model/graphrag_t_2/output/20250204-200327/artifacts\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = path\n",
    "LANCEDB_URI = f\"/Users/jun/GitStudy/Data_4/Data/project5/model/graphrag_t_2/output/lancedb\"\n",
    "\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "RELATIONSHIP_TABLE = \"create_final_relationships\"\n",
    "COVARIATE_TABLE = \"create_final_covariates\"\n",
    "TEXT_UNIT_TABLE = \"create_final_text_units\"\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity count: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>title</th>\n",
       "      <th>community</th>\n",
       "      <th>level</th>\n",
       "      <th>degree</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a73a3176-fcbc-4164-b627-d7fcab2f4208</td>\n",
       "      <td>0</td>\n",
       "      <td>UGWORT TIGER GRASS COLOR CORRECTING TREATMENT ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6090f14-116c-4e03-acdc-8a09a7601d99</td>\n",
       "      <td>1</td>\n",
       "      <td>GOOD FOR OILY SKIN</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88872b66-0c1d-4f36-a13f-d02a78185d5b</td>\n",
       "      <td>2</td>\n",
       "      <td>REDNESS REDUCING</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3c6d86ba-46cb-4d67-aa31-3bdd75ee74e5</td>\n",
       "      <td>3</td>\n",
       "      <td>REDUCES IRRITATION</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9aa4edf8-1c7a-4f41-b9b7-47fa8c3ebd11</td>\n",
       "      <td>4</td>\n",
       "      <td>ACNE FIGHTING</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  human_readable_id  \\\n",
       "0  a73a3176-fcbc-4164-b627-d7fcab2f4208                  0   \n",
       "1  b6090f14-116c-4e03-acdc-8a09a7601d99                  1   \n",
       "2  88872b66-0c1d-4f36-a13f-d02a78185d5b                  2   \n",
       "3  3c6d86ba-46cb-4d67-aa31-3bdd75ee74e5                  3   \n",
       "4  9aa4edf8-1c7a-4f41-b9b7-47fa8c3ebd11                  4   \n",
       "\n",
       "                                               title  community  level  \\\n",
       "0  UGWORT TIGER GRASS COLOR CORRECTING TREATMENT ...         -1      0   \n",
       "1                                 GOOD FOR OILY SKIN         -1      0   \n",
       "2                                   REDNESS REDUCING          0      0   \n",
       "3                                 REDUCES IRRITATION         -1      0   \n",
       "4                                      ACNE FIGHTING         -1      0   \n",
       "\n",
       "   degree    x    y  \n",
       "0       0  NaN  NaN  \n",
       "1       0  NaN  NaN  \n",
       "2       1  0.0  0.0  \n",
       "3       0  NaN  NaN  \n",
       "4       0  NaN  NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read nodes table to get community and degree data\n",
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "\n",
    "# load description embeddings to an in-memory lancedb vectorstore\n",
    "# to connect to a remote db, specify url and port values.\n",
    "description_embedding_store = LanceDBVectorStore(\n",
    "    collection_name=\"default-entity-description\",\n",
    ")\n",
    "description_embedding_store.connect(db_uri=LANCEDB_URI)\n",
    "\n",
    "print(f\"Entity count: {len(entity_df)}\")\n",
    "entity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship count: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>description</th>\n",
       "      <th>weight</th>\n",
       "      <th>combined_degree</th>\n",
       "      <th>text_unit_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16ebc622-875d-4831-a9f4-35ae87c99f84</td>\n",
       "      <td>0</td>\n",
       "      <td>REDNESS REDUCING</td>\n",
       "      <td>ADVANCED SNAIL 96 MUCIN POWER ESSENCE</td>\n",
       "      <td>The product description states that it reduces...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[e60c5576771b6969e5cc28927826c697ab796cca65489...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  human_readable_id            source  \\\n",
       "0  16ebc622-875d-4831-a9f4-35ae87c99f84                  0  REDNESS REDUCING   \n",
       "\n",
       "                                  target  \\\n",
       "0  ADVANCED SNAIL 96 MUCIN POWER ESSENCE   \n",
       "\n",
       "                                         description  weight  combined_degree  \\\n",
       "0  The product description states that it reduces...     2.0                2   \n",
       "\n",
       "                                       text_unit_ids  \n",
       "0  [e60c5576771b6969e5cc28927826c697ab796cca65489...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship_df = pd.read_parquet(f\"{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet\")\n",
    "relationships = read_indexer_relationships(relationship_df)\n",
    "\n",
    "print(f\"Relationship count: {len(relationship_df)}\")\n",
    "relationship_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jun/GitStudy/Data_4/Data/project5/model/graphrag_t_2/output/20250204-200327/artifacts/create_final_covariates.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# NOTE: covariates are turned off by default, because they generally need prompt tuning to be valuable\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Please see the GRAPHRAG_CLAIM_* settings\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m covariate_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mINPUT_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCOVARIATE_TABLE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m claims \u001b[38;5;241m=\u001b[39m read_indexer_covariates(covariate_df)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClaim records: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(claims)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/pandas/io/parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/pandas/io/parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jun/GitStudy/Data_4/Data/project5/model/graphrag_t_2/output/20250204-200327/artifacts/create_final_covariates.parquet'"
     ]
    }
   ],
   "source": [
    "# NOTE: covariates are turned off by default, because they generally need prompt tuning to be valuable\n",
    "# Please see the GRAPHRAG_CLAIM_* settings\n",
    "covariate_df = pd.read_parquet(f\"{INPUT_DIR}/{COVARIATE_TABLE}.parquet\")\n",
    "\n",
    "claims = read_indexer_covariates(covariate_df)\n",
    "\n",
    "print(f\"Claim records: {len(claims)}\")\n",
    "covariates = {\"claims\": claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default-community-full_content': <llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x34410d990>,\n",
       " 'default-entity-description': <llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x3440cee50>,\n",
       " 'default-text_unit-text': <llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x3440cd310>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = {name: VectorStoreIndex.from_vector_store(store, storage_context=storage_contexts[name]) for name, store in vector_stores.items()}\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default-community-full_content': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x341f87210>,\n",
       " 'default-entity-description': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x3440c5890>,\n",
       " 'default-text_unit-text': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x3440c56d0>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# âœ… ì—¬ëŸ¬ í…Œì´ë¸”ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ Query ì—”ì§„ì„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì €ì¥\n",
    "query_engines = {name: index.as_query_engine() for name, index in indexes.items()}\n",
    "query_engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ íŒŒì¼ ì—…ë¡œë“œ í›„ ë¬¸ì„œ ì²˜ë¦¬\n",
    "def process_uploaded_files(files):\n",
    "    \"\"\"ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼ì„ ì²˜ë¦¬í•˜ì—¬ LlamaIndexì— ì¶”ê°€\"\"\"\n",
    "    if not files:\n",
    "        return None  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¬´ì‹œ\n",
    "\n",
    "    # íŒŒì¼ ì €ì¥ ê²½ë¡œ\n",
    "    upload_dir = \"uploaded_files\"\n",
    "    os.makedirs(upload_dir, exist_ok=True)\n",
    "\n",
    "    # ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥\n",
    "    file_paths = []\n",
    "    for file in files:\n",
    "        file_path = os.path.join(upload_dir, file.name)\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "        # Parquet íŒŒì¼ ì²˜ë¦¬\n",
    "        if file.name.endswith(\".parquet\"):\n",
    "            try:\n",
    "                df = pd.read_parquet(file)  # âœ… Parquet íŒŒì¼ì„ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "                text_data = df.to_string(index=False)  # âœ… DataFrameì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "                text_file_path = file_path.replace(\".parquet\", \".txt\")  # ë³€í™˜ëœ íŒŒì¼ëª…\n",
    "                with open(text_file_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "                    text_file.write(text_data)  # âœ… TXT íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ LlamaIndexê°€ ì½ì„ ìˆ˜ ìˆë„ë¡ ë³€í™˜\n",
    "                file_paths.append(text_file_path)  # ë³€í™˜ëœ íŒŒì¼ì„ ì¶”ê°€\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Parquet íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨: {e}\")\n",
    "                return None  # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ\n",
    "\n",
    "        else:\n",
    "            # ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ íŒŒì¼ ì €ì¥\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(file.read())\n",
    "\n",
    "    # ğŸ“Œ ìƒˆ ë¬¸ì„œ ì¸ë±ì‹±\n",
    "    documents = SimpleDirectoryReader(input_files=file_paths).load_data()\n",
    "    new_index = VectorStoreIndex.from_documents(documents)\n",
    "    return new_index.as_query_engine()\n",
    "\n",
    "# ğŸ“Œ ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬\n",
    "def answer(message, history, files):\n",
    "    \n",
    "    global query_engines\n",
    "    \"\"\"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ê³ , ê¸°ì¡´ GraphRAG ë°ì´í„° + ì—…ë¡œë“œëœ ë¬¸ì„œ ë°ì´í„°ë¡œ ë‹µë³€\"\"\"\n",
    "    \n",
    "    # ê¸°ì¡´ GraphRAG ë°ì´í„° (ì—¬ëŸ¬ í…Œì´ë¸”ì—ì„œ ì²˜ë¦¬)\n",
    "    query_engine_list = list(query_engines.values())  \n",
    "    \n",
    "    # ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆì„ ê²½ìš° ìƒˆë¡­ê²Œ ì¸ë±ì‹±í•˜ì—¬ ì¶”ê°€\n",
    "    new_query_engine = process_uploaded_files(files)\n",
    "    if new_query_engine:\n",
    "        query_engine_list.append(new_query_engine)\n",
    "        query_engines[\"uploaded_files\"] = new_query_engine # âœ… ì—…ë¡œë“œí•œ ë¬¸ì„œë„ ì¶”ê°€\n",
    "    \n",
    "    # ëª¨ë“  ì¿¼ë¦¬ ì—”ì§„ì—ì„œ ì§ˆì˜ ìˆ˜í–‰\n",
    "    responses = []\n",
    "    for qe in query_engine_list:\n",
    "        print(qe)\n",
    "        if hasattr(qe, 'query'):  # query ì—”ì§„ì´ query ë©”ì„œë“œë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸\n",
    "            responses.append(qe.query(message[\"text\"]))\n",
    "        else:\n",
    "            print(f\"âŒ {qe}ëŠ” query ë©”ì„œë“œë¥¼ ê°€ì§€ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ğŸ“Œ ì‘ë‹µì„ ì¢…í•©í•˜ì—¬ ë°˜í™˜\n",
    "    return \"\\n\\n---\\n\\n\".join([str(resp) for resp in responses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/gradio/helpers.py:968: UserWarning: Unexpected argument. Filling with None.\n",
      "  warnings.warn(\"Unexpected argument. Filling with None.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x341f87210>\n",
      "relation :  {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/vector_stores/lancedb/base.py\", line 529, in query\n",
      "    print(f\"item_json : {item_json}\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/core/vector_stores/utils.py\", line 70, in metadata_dict_to_node\n",
      "    raise ValueError(\"Node content not found in metadata dict.\")\n",
      "ValueError: Node content not found in metadata dict.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/pandas/core/indexes/base.py\", line 3805, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'doc_id'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/gradio/queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/gradio/blocks.py\", line 2051, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/gradio/blocks.py\", line 1596, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/gradio/utils.py\", line 850, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/gradio/chat_interface.py\", line 861, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/29/5wmqbm4j3x10qv5vgm_bm8f80000gn/T/ipykernel_69986/2332650835.py\", line 60, in answer\n",
      "    responses.append(qe.query(message[\"text\"]))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/core/base/base_query_engine.py\", line 52, in query\n",
      "    query_result = self._query(str_or_query_bundle)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py\", line 178, in _query\n",
      "    nodes = self.retrieve(query_bundle)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/core/query_engine/retriever_query_engine.py\", line 133, in retrieve\n",
      "    nodes = self._retriever.retrieve(query_bundle)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/core/base/base_retriever.py\", line 245, in retrieve\n",
      "    nodes = self._retrieve(query_bundle)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 321, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/core/indices/vector_store/retrievers/retriever.py\", line 103, in _retrieve\n",
      "    return self._get_nodes_with_embeddings(query_bundle)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/core/indices/vector_store/retrievers/retriever.py\", line 180, in _get_nodes_with_embeddings\n",
      "    query_result = self._vector_store.query(query, **self._kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/llama_index/vector_stores/lancedb/base.py\", line 563, in query\n",
      "    metadata=metadata,\n",
      "                    ^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/pandas/core/series.py\", line 1121, in __getitem__\n",
      "    return self._get_value(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/pandas/core/series.py\", line 1237, in _get_value\n",
      "    loc = self.index.get_loc(label)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/leo4study/lib/python3.11/site-packages/pandas/core/indexes/base.py\", line 3812, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'doc_id'\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •\n",
    "demo = gr.ChatInterface(\n",
    "    answer,\n",
    "    type=\"messages\",\n",
    "    title=\"GraphRAG + Ollama RAG Chatbot\",\n",
    "    description=\"GraphRAGì—ì„œ ìƒì„±í•œ LanceDB ë°ì´í„°ì™€ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œë¥¼ í™œìš©í•œ Ollama ê¸°ë°˜ RAG Chatbot!\",\n",
    "    textbox=gr.MultimodalTextbox(file_types=[\".pdf\", \".txt\"]),\n",
    "    multimodal=True  # íŒŒì¼ ì—…ë¡œë“œ í—ˆìš©\n",
    ")\n",
    "\n",
    "# ğŸ“Œ ì‹¤í–‰\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leo4study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
